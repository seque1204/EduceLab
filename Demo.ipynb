{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6d0963-4b8f-4f61-8359-4c3c056b51c9",
   "metadata": {},
   "source": [
    "# Functions used in getting data_list\n",
    "- Adds each file in folder into data_list object. Adds the image array as well as image class based on scroll number and filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2517f55-e5d3-4ea7-8f34-8715d55febe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_class(filename):\n",
    "    # A dictionary mapping substrings to their corresponding classes\n",
    "    class_map = {\n",
    "        \"862\": 0,\n",
    "        \n",
    "        \"0026\": 1,\n",
    "        \"0089\": 1,\n",
    "        \"0155\": 1,\n",
    "        '0339': 1,\n",
    "        \"0353\": 1,\n",
    "        \"0817\": 1,\n",
    "        '1005': 1,\n",
    "        \"1044\": 1,\n",
    "        \"1413\": 1,\n",
    "        \n",
    "        \"1636\": 2,\n",
    "        \n",
    "        '1670': 3\n",
    "    }\n",
    "    \n",
    "    # Iterate through the dictionary to find a match\n",
    "    for key, class_name in class_map.items():\n",
    "        if key in filename:\n",
    "            return class_name\n",
    "    \n",
    "    # Return a default value if no match is found\n",
    "    return \"unknown_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e56586e-8dc6-4fb1-b180-a6fd07a97b02",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_zarr_arrays(directory):\n",
    "    # List to store each transposed Zarr array\n",
    "    data_list = []\n",
    "    # Counter to track the number of files processed\n",
    "    file_count = 1\n",
    "    max_files = 999999 \n",
    "\n",
    "    # Get the total number of directories (Zarr files) in the directory\n",
    "    total_files = sum(1 for filename in os.listdir(directory) if os.path.isdir(os.path.join(directory, filename)))\n",
    "\n",
    "     # Iterate through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Check if it's a directory (since Zarr files are typically stored in directories)\n",
    "        if os.path.isdir(file_path):\n",
    "            print(f\"Processing file #{file_count}/{total_files} at {os.path.basename(file_path)}\")\n",
    "            try:\n",
    "                # Open the Zarr file\n",
    "                #print(f\"Opening {file_path}\")\n",
    "                zarr_file = zarr.open(file_path, mode='r')\n",
    "\n",
    "                # Use Zarr attributes to retrieve the class of the image\n",
    "                #tests the embedding of metadata to files when importing from globus\n",
    "                if 'class' in zarr_file.attrs:\n",
    "                    image_class = zarr_file.attrs['class']\n",
    "                else:\n",
    "                    image_class = determine_class(filename)\n",
    "                    print(f\"No class attribute found in {filename}; assigning class {image_class} using function.\\n\")\n",
    "\n",
    "                #Create the Zarray\n",
    "                if zarr_file.shape[-1] == 16:\n",
    "                    #actual image data\n",
    "                    zarr_array = zarr_file\n",
    "                elif zarr_file.shape[0] == 16:\n",
    "                    #converts (channels, h, w) to (h,w,channels)\n",
    "                    zarr_array = np.transpose(zarr_file, (1,2,0))\n",
    "                else:\n",
    "                    print(\"Zarr file is not in any correct format\")\n",
    "        \n",
    "                # Store the data along with its metadata\n",
    "                data_list.append({\n",
    "                    'image_data': zarr_array,  # The actual image data\n",
    "                    'class': image_class,            # The class determined\n",
    "                    'filename': filename             # The original filename\n",
    "                })\n",
    "                \n",
    "                # Increment the file count\n",
    "                file_count += 1\n",
    "                # Stop if the maximum number of files has been processed\n",
    "                if file_count >= max_files:\n",
    "                    print(\"Reached file limit set my user. Verify variable 'max_files'\")\n",
    "                    break\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Handle cases where the file cannot be opened as a Zarr file\n",
    "                print(f\"Could not read {filename} as a Zarr file. Error: {e}\")\n",
    "    print(\"Done\")\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145b40c7-8bd4-4db8-b6bd-b23607f6d3b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "from collections import Counter\n",
    "def get_data_list():\n",
    "    zarr_dir = \"D:\\EduceLab_HDD\\ImportsFromGlobus\\zarrs\"\n",
    "    data_list = [] \n",
    "    data_list = create_zarr_arrays(zarr_dir)\n",
    "\n",
    "    print(\"Created data_list succesfully. Summary of data_list: \\n\")    \n",
    "    \n",
    "    # Get all unique shapes\n",
    "    unique_shapes = {item['image_data'].shape for item in data_list}\n",
    "    print(\"Unique Shapes:\")\n",
    "    for shape in unique_shapes:\n",
    "        print(shape)\n",
    "    \n",
    "    # Count the occurrences of each class\n",
    "    #create a dictionary for the class count to be used for uniform subarea distribution\n",
    "    class_counts = Counter(item['class'] for item in data_list)\n",
    "    class_counts_dic = {}\n",
    "    print(\"\\nClass Counts:\")\n",
    "    for image_class, count in class_counts.items():\n",
    "        class_counts_dic[image_class] = count\n",
    "        print(f\"{image_class}: {count}\")\n",
    "    print(class_counts_dic)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e5283-c67b-4e57-8822-beb4f7609aba",
   "metadata": {},
   "source": [
    "### Results from create zarrays are consistent with expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82b54e-0a0e-497a-9f96-6753ef4b27ce",
   "metadata": {},
   "source": [
    "# Functions used in getting balanced dataset\n",
    "- get_centered_boudaries, returns X boundaries of given size.\n",
    "- extract_subarea, returns a slice of the image with the boundaries given\n",
    "- subarea_generator, given data_list, it yields a subarea and label\n",
    "- create_dataset, uses subarea_generator to create a fataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890a16e2-d6e7-46f5-bc39-d02e2b16fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e85fe3b-650e-4e85-b6a2-2740d882b62a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_centered_boudaries(image_shape, subarea_size, subareas_per_image):\n",
    "  \"\"\"\n",
    "    Generate a list of bounding boxes centered around the middle of an image.\n",
    "\n",
    "    Args:\n",
    "        image_shape (tuple): A tuple representing the dimensions of the image (height, width, channels).\n",
    "        subarea_size (tuple): A tuple representing the height and width of each subarea.\n",
    "        subareas_per_image (int): The number of subareas to generate within the image.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, each representing the bounding coordinates of a subarea within the image.\n",
    "              Each tuple has the format (top_y, bottom_y, left_x, right_x).\n",
    "\n",
    "    Functionality:\n",
    "        - Calculates the center of the image using its dimensions.\n",
    "        - Defines a standard deviation to control the spread of subarea locations around the center.\n",
    "        - For each subarea, generates top-left coordinates based on a normal distribution centered around\n",
    "          the image's midpoint.\n",
    "        - Clips the coordinates to ensure each subarea is within the image boundaries.\n",
    "        - Returns the list of boundaries, with each subarea centered around the middle, following a normal distribution.\n",
    "\n",
    "    Example:\n",
    "        If image_shape = (200, 200, 3), subarea_size = (50, 50), and subareas_per_image = 5,\n",
    "        the function will return 5 bounding boxes focused around the center of the image, with each box\n",
    "        sized 50x50 pixels.\n",
    "  \"\"\"\n",
    "\n",
    "  height, width, channel = image_shape\n",
    "\n",
    "  # Define the mean and normal distribution (center of image)\n",
    "  mean_x = width // 2\n",
    "  mean_y = height // 2\n",
    "\n",
    "  # Define the standard deviation (smaller values will focus more on center)\n",
    "  std_x = width // 8\n",
    "  std_y = height // 8\n",
    "\n",
    "  boundaries_list = []\n",
    "\n",
    "  for _ in range(subareas_per_image):\n",
    "    # Generate random values from the normal distribution\n",
    "    top_left_x = int(np.clip(np.random.normal(loc = mean_x, scale = std_x), 0, width - subarea_size[1]))\n",
    "    top_left_y = int(np.clip(np.random.normal(loc = mean_y, scale = std_y), 0, height - subarea_size[0]))\n",
    "    boundaries_list.append((top_left_y, top_left_y + subarea_size[0], top_left_x, top_left_x + subarea_size[1]))\n",
    "  return boundaries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c1d019-ecfe-4e4c-9f06-99967c223a79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_subarea(image, boundaries):\n",
    "  \"\"\"\n",
    "    Extract a subarea from an image based on given boundary coordinates.\n",
    "\n",
    "    Args:\n",
    "        image (numpy array): The input image array from which a subarea will be extracted.\n",
    "                             Expected shape is (height, width, channels).\n",
    "        boundaries (tuple): A tuple representing the coordinates of the subarea to extract.\n",
    "                            The format should be (top_left_y, bottom_right_y, top_left_x, bottom_right_x),\n",
    "                            where:\n",
    "                              - top_left_y: The top boundary row index.\n",
    "                              - bottom_right_y: The bottom boundary row index.\n",
    "                              - top_left_x: The left boundary column index.\n",
    "                              - bottom_right_x: The right boundary column index.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: The extracted subarea as a slice of the original image, retaining\n",
    "                     the same number of channels.\n",
    "\n",
    "    Functionality:\n",
    "        - Slices the input image array according to the specified boundaries.\n",
    "        - Returns only the region within the defined boundaries, with the same number\n",
    "          of color channels as the input image.\n",
    "\n",
    "    Example:\n",
    "        If boundaries = (50, 100, 30, 80), the function will return the portion of the\n",
    "        image from row 50 to 100 and column 30 to 80.\n",
    "    \"\"\"\n",
    "\n",
    "  top_left_y, bottom_right_y, top_left_x, bottom_right_x = boundaries\n",
    "  subarea = image[top_left_y:bottom_right_y, top_left_x:bottom_right_x, :]\n",
    "  return subarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5250345-651d-4e2c-b65c-302e3f199bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subarea_generator(data_list, subarea_size=(128,128,16),subareas_per_image = 1000):\n",
    "  for data_item in data_list:\n",
    "    #Extract image and label\n",
    "    multi_channel_image = data_item['image_data']\n",
    "    image_class = data_item['class']\n",
    "    #filename = data_item['filename']\n",
    "\n",
    "    #generate centered boundaries\n",
    "    boundaries_list = get_centered_boudaries(multi_channel_image.shape, subarea_size, subareas_per_image)\n",
    "\n",
    "    #Yield each subarea and class as tensors\n",
    "    for boundaries in boundaries_list:\n",
    "      subarea = extract_subarea(multi_channel_image, boundaries)\n",
    "      yield subarea, image_class#, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9b2a55-23b6-4b46-a02f-8dd8f33c074d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(data_list, subarea_size=(128,128,16),subareas_per_image = 1000):\n",
    "  \"\"\"\n",
    "    Create a TensorFlow dataset of image subareas using a generator function.\n",
    "\n",
    "    Args:\n",
    "        data_list (list): A list containing the image data or file paths to images. Each entry corresponds to an image.\n",
    "        subarea_size (tuple, optional): The desired dimensions of each subarea (height, width). Defaults to (32, 32).\n",
    "        subareas_per_image (int, optional): The number of subareas to generate per image. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A TensorFlow dataset where each element is a tuple consisting of:\n",
    "                         - A tensor of shape (subarea_height, subarea_width, 16) representing\n",
    "                           a subarea of the original image.\n",
    "                         - An integer label associated with the subarea, of type int32.\n",
    "  \"\"\"\n",
    "  dataset = tf.data.Dataset.from_generator(\n",
    "      lambda: subarea_generator(data_list, subarea_size, subareas_per_image),\n",
    "      output_signature=(\n",
    "          # The 16 here is the number of channels.\n",
    "          tf.TensorSpec(shape=(subarea_size[0], subarea_size[1], subarea_size[2]), dtype=tf.float32),\n",
    "          tf.TensorSpec(shape=(), dtype=tf.int32)#,\n",
    "          #tf.TensorSpec(shape=(), dtype=tf.string)  including filename is causing problems when feeding data into model, ignore for now\n",
    "      )\n",
    "  )\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc65e6e8-1773-40f6-ab6d-d9d714d99be1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_balanced_dataset(data_list, subarea_size, size_wanted=50):\n",
    "    from collections import defaultdict\n",
    "    #Gets the amount of unique classes\n",
    "    unique_classes = set(item['class'] for item in data_list)\n",
    "    print(f\"Unique classes: {unique_classes}\")\n",
    "    # Create a dictionary to hold data_list for each class\n",
    "    data_lists = defaultdict(list)\n",
    "    \n",
    "    # Populate the dictionary\n",
    "    for item in data_list:\n",
    "        class_label = item['class']\n",
    "        data_lists[class_label].append(item)\n",
    "\n",
    "    #Convert back to lists of lists\n",
    "    data_lists_as_list = [data_lists[class_label] for class_label in sorted(unique_classes)]\n",
    "    print(f\"Number of class-specific lists: {len(data_lists_as_list)}\")    \n",
    "    xs = []\n",
    "    for data_list in data_lists_as_list:  # Iterate over each class-specific data list\n",
    "        x = (size_wanted // 10) / len(data_list)  # Compute x for the current data list\n",
    "        x = round(x * 10)\n",
    "        xs.append(x)\n",
    "        \n",
    "    datasets = []  # List to store all created datasets\n",
    "    for data_list, x in zip(data_lists_as_list, xs):\n",
    "        dataset = create_dataset(data_list, subarea_size=subarea_size, subareas_per_image=x)\n",
    "        if sum(1 for _ in dataset) > 0:\n",
    "            datasets.append(dataset)\n",
    "        else:\n",
    "            print(f\"Warning: Empty dataset for class {data_list[0]['class']}.\")\n",
    "\n",
    "# Inspect datasets\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        print(f\"Inspecting Dataset {i}:\")\n",
    "        dataset_size = sum(1 for _ in dataset)\n",
    "        print(f\"Dataset {i} size: {dataset_size}\")\n",
    "        for image, label in dataset.take(1):  # Inspect the first sample\n",
    "            print(f\"  Image shape: {image.shape}, Label: {label}\")\n",
    "\n",
    "    print(\"Finished creating datasets.\")\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b856dd7-e3fa-45bc-80a3-149237afd9ed",
   "metadata": {},
   "source": [
    "# Functions used to split into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647bd147-6489-456f-b4a6-a82abdc71eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_class_counts(dataset):\n",
    "    \"\"\"Count occurrences of each class in the dataset.\"\"\"\n",
    "    class_counts = Counter()\n",
    "    for _, labels in dataset.unbatch():  # Unbatch to access individual samples\n",
    "        class_counts[int(labels.numpy())] += 1\n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "915ecba4-674a-41cc-ba5b-30c0e44cee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validation(datasets, split_ratio=0.8):\n",
    "    train_datasets = []\n",
    "    validation_datasets = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        # Count total samples in the dataset\n",
    "        total_samples = sum(1 for _ in dataset)\n",
    "        \n",
    "        # Compute split index\n",
    "        split_index = int(total_samples * split_ratio)\n",
    "        \n",
    "        # Split the dataset\n",
    "        train_dataset = dataset.take(split_index)  # First `split_index` samples\n",
    "        validation_dataset = dataset.skip(split_index)  # Remaining samples\n",
    "        \n",
    "        # Append to respective lists\n",
    "        train_datasets.append(train_dataset)\n",
    "        validation_datasets.append(validation_dataset)\n",
    "    \n",
    "    return train_datasets, validation_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19909b00-fd49-4d93-8c94-842c78123c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset, batch_size, split_ratio):\n",
    "    train_datasets, validation_datasets = split_train_validation(dataset, split_ratio)\n",
    "    # Shuffle and batch\n",
    "    train_datasets = [train.shuffle(buffer_size=100).batch(batch_size=batch_size) for train in train_datasets]\n",
    "    validation_datasets = [val.batch(batch_size=batch_size) for val in validation_datasets]\n",
    "    \n",
    "    # Combine into unified datasets\n",
    "    full_train_dataset = train_datasets[0]\n",
    "    for train in train_datasets[1:]:\n",
    "        full_train_dataset = full_train_dataset.concatenate(train)\n",
    "    \n",
    "    full_validation_dataset = validation_datasets[0]\n",
    "    for val in validation_datasets[1:]:\n",
    "        full_validation_dataset = full_validation_dataset.concatenate(val)\n",
    "\n",
    "    # Calculate and print sizes\n",
    "    train_size = sum(1 for _ in full_train_dataset)\n",
    "    val_size = sum(1 for _ in full_validation_dataset)\n",
    "    print(f\"Final train dataset size: {train_size} batches\")\n",
    "    print(f\"Final validation dataset size: {val_size} batches\")\n",
    "\n",
    "    # Get class counts\n",
    "    train_class_counts = get_class_counts(full_train_dataset)\n",
    "    val_class_counts = get_class_counts(full_validation_dataset)\n",
    "\n",
    "    print(\"Class counts in training dataset:\", train_class_counts)\n",
    "    print(\"Class counts in validation dataset:\", val_class_counts)\n",
    "\n",
    "    return full_train_dataset, full_validation_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef8d2a-749e-41b1-8358-1353ba325c24",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609a647e-98c5-4a6c-a1aa-1da4f70d6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(subarea_size = (128,128,16)):\n",
    "    #Define a simple CNN model for demo\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(subarea_size[0], subarea_size[1], subarea_size[2])),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')  # 4 classes\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "808fc3c4-ee89-4fcd-a20a-e6683c949c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, validation_data, epochs):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_data,\n",
    "                        epochs=epochs,\n",
    "                        validation_data = validation_data)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6e3e634-35d6-4c6c-a070-d71f5054b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eba92ac1-0ee0-4d39-a2de-3326e78600a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(history):\n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65ee2f-1dda-468b-8619-1c2c859635e9",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542a1a65-e307-453f-a0e7-3a533cbeaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file #1/65 at PHerc0026Cr01.zarr\n",
      "No class attribute found in PHerc0026Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #2/65 at PHerc0026Cr02.zarr\n",
      "No class attribute found in PHerc0026Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #3/65 at PHerc0026Cr03.zarr\n",
      "No class attribute found in PHerc0026Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #4/65 at PHerc0026Cr04.zarr\n",
      "No class attribute found in PHerc0026Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #5/65 at PHerc0026Cr05.zarr\n",
      "No class attribute found in PHerc0026Cr05.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #6/65 at PHerc0026Cr06.zarr\n",
      "No class attribute found in PHerc0026Cr06.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #7/65 at PHerc0026Cr07.zarr\n",
      "No class attribute found in PHerc0026Cr07.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #8/65 at PHerc0089Cr01.zarr\n",
      "No class attribute found in PHerc0089Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #9/65 at PHerc0089Cr02.zarr\n",
      "No class attribute found in PHerc0089Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #10/65 at PHerc0089Cr03.zarr\n",
      "No class attribute found in PHerc0089Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #11/65 at PHerc0089Cr04.zarr\n",
      "No class attribute found in PHerc0089Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #12/65 at PHerc0089Cr05.zarr\n",
      "No class attribute found in PHerc0089Cr05.zarr; assigning class 1 using function.\n",
      "\n",
      "Zarr file is not in any correct format\n",
      "Processing file #13/65 at PHerc0155Cr01.zarr\n",
      "No class attribute found in PHerc0155Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #14/65 at PHerc0155Cr02.zarr\n",
      "No class attribute found in PHerc0155Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #15/65 at PHerc0155Cr03.zarr\n",
      "No class attribute found in PHerc0155Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #16/65 at PHerc0155Cr04.zarr\n",
      "No class attribute found in PHerc0155Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #17/65 at PHerc0155Cr05.zarr\n",
      "No class attribute found in PHerc0155Cr05.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #18/65 at PHerc0339Cr01.zarr\n",
      "No class attribute found in PHerc0339Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #19/65 at PHerc0339Cr02.zarr\n",
      "No class attribute found in PHerc0339Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #20/65 at PHerc0339Cr03.zarr\n",
      "No class attribute found in PHerc0339Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #21/65 at PHerc0339Cr04.zarr\n",
      "No class attribute found in PHerc0339Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #22/65 at PHerc0339Cr05.zarr\n",
      "No class attribute found in PHerc0339Cr05.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #23/65 at PHerc0339Cr06.zarr\n",
      "No class attribute found in PHerc0339Cr06.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #24/65 at PHerc0353Cr01.zarr\n",
      "No class attribute found in PHerc0353Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #25/65 at PHerc0353Cr02.zarr\n",
      "No class attribute found in PHerc0353Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #26/65 at PHerc0353Cr03.zarr\n",
      "No class attribute found in PHerc0353Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #27/65 at PHerc0353Cr04.zarr\n",
      "No class attribute found in PHerc0353Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #28/65 at PHerc0817Cr01.zarr\n",
      "No class attribute found in PHerc0817Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #29/65 at PHerc0817Cr02.zarr\n",
      "No class attribute found in PHerc0817Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #30/65 at PHerc0817Cr03.zarr\n",
      "No class attribute found in PHerc0817Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #31/65 at PHerc0817Cr04.zarr\n",
      "No class attribute found in PHerc0817Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #32/65 at PHerc0817Cr05.zarr\n",
      "No class attribute found in PHerc0817Cr05.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #33/65 at PHerc0817Cr06.zarr\n",
      "No class attribute found in PHerc0817Cr06.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #34/65 at PHerc1005Cr01.zarr\n",
      "No class attribute found in PHerc1005Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #35/65 at PHerc1005Cr02.zarr\n",
      "No class attribute found in PHerc1005Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #36/65 at PHerc1005Cr03.zarr\n",
      "No class attribute found in PHerc1005Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #37/65 at PHerc1005Cr04.zarr\n",
      "No class attribute found in PHerc1005Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Zarr file is not in any correct format\n",
      "Processing file #38/65 at PHerc1005Cr05.zarr\n",
      "No class attribute found in PHerc1005Cr05.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #39/65 at PHerc1044Cr01.zarr\n",
      "No class attribute found in PHerc1044Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #40/65 at PHerc1044Cr02.zarr\n",
      "No class attribute found in PHerc1044Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #41/65 at PHerc1044Cr03.zarr\n",
      "No class attribute found in PHerc1044Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #42/65 at PHerc1044Cr04.zarr\n",
      "No class attribute found in PHerc1044Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #43/65 at PHerc1044Cr05.zarr\n",
      "No class attribute found in PHerc1044Cr05.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #44/65 at PHerc1044Cr06.zarr\n",
      "No class attribute found in PHerc1044Cr06.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #45/65 at PHerc1044Cr07.zarr\n",
      "No class attribute found in PHerc1044Cr07.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #46/65 at PHerc1044Cr08.zarr\n",
      "No class attribute found in PHerc1044Cr08.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #47/65 at PHerc1044Cr09.zarr\n",
      "No class attribute found in PHerc1044Cr09.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #48/65 at PHerc1044Cr10.zarr\n",
      "No class attribute found in PHerc1044Cr10.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #49/65 at PHerc1044Cr11.zarr\n",
      "No class attribute found in PHerc1044Cr11.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #50/65 at PHerc1044Cr12.zarr\n",
      "No class attribute found in PHerc1044Cr12.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #51/65 at PHerc1044Cr13.zarr\n",
      "No class attribute found in PHerc1044Cr13.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #52/65 at PHerc1413Cr01.zarr\n",
      "No class attribute found in PHerc1413Cr01.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #53/65 at PHerc1413Cr02.zarr\n",
      "No class attribute found in PHerc1413Cr02.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #54/65 at PHerc1413Cr03.zarr\n",
      "No class attribute found in PHerc1413Cr03.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #55/65 at PHerc1413Cr04.zarr\n",
      "No class attribute found in PHerc1413Cr04.zarr; assigning class 1 using function.\n",
      "\n",
      "Processing file #56/65 at PHerc1636CrScorzeda.zarr\n",
      "No class attribute found in PHerc1636CrScorzeda.zarr; assigning class 2 using function.\n",
      "\n",
      "Processing file #57/65 at PHerc1670Cr01.zarr\n",
      "No class attribute found in PHerc1670Cr01.zarr; assigning class 3 using function.\n",
      "\n",
      "Processing file #58/65 at PHerc1670Cr02.zarr\n",
      "No class attribute found in PHerc1670Cr02.zarr; assigning class 3 using function.\n",
      "\n",
      "Processing file #59/65 at PHerc1670Cr03.zarr\n",
      "No class attribute found in PHerc1670Cr03.zarr; assigning class 3 using function.\n",
      "\n",
      "Processing file #60/65 at PHerc862Cr01.zarr\n",
      "No class attribute found in PHerc862Cr01.zarr; assigning class 0 using function.\n",
      "\n",
      "Processing file #61/65 at PHerc862Cr02.zarr\n",
      "No class attribute found in PHerc862Cr02.zarr; assigning class 0 using function.\n",
      "\n",
      "Processing file #62/65 at PHerc862Cr03.zarr\n",
      "No class attribute found in PHerc862Cr03.zarr; assigning class 0 using function.\n",
      "\n",
      "Processing file #63/65 at PHerc862Cr04.zarr\n",
      "No class attribute found in PHerc862Cr04.zarr; assigning class 0 using function.\n",
      "\n",
      "Processing file #64/65 at PHerc862Cr05.zarr\n",
      "No class attribute found in PHerc862Cr05.zarr; assigning class 0 using function.\n",
      "\n",
      "Processing file #65/65 at PHerc862Cr06.zarr\n",
      "No class attribute found in PHerc862Cr06.zarr; assigning class 0 using function.\n",
      "\n",
      "Done\n",
      "Created data_list succesfully. Summary of data_list: \n",
      "\n",
      "Unique Shapes:\n",
      "(6132, 8176, 16)\n",
      "\n",
      "Class Counts:\n",
      "1: 55\n",
      "2: 1\n",
      "3: 3\n",
      "0: 6\n",
      "{1: 55, 2: 1, 3: 3, 0: 6}\n"
     ]
    }
   ],
   "source": [
    "data_list = get_data_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67757c96-ef2b-487c-884e-52ba2fb7bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: {0, 1, 2, 3}\n",
      "Number of class-specific lists: 4\n",
      "Inspecting Dataset 0:\n",
      "Dataset 0 size: 102\n",
      "  Image shape: (128, 128, 16), Label: 0\n",
      "Inspecting Dataset 1:\n",
      "Dataset 1 size: 110\n",
      "  Image shape: (128, 128, 16), Label: 1\n",
      "Inspecting Dataset 2:\n",
      "Dataset 2 size: 100\n",
      "  Image shape: (128, 128, 16), Label: 2\n",
      "Inspecting Dataset 3:\n",
      "Dataset 3 size: 99\n",
      "  Image shape: (128, 128, 16), Label: 3\n",
      "Finished creating datasets.\n"
     ]
    }
   ],
   "source": [
    "subarea_size = (128,128,16)\n",
    "num_of_subareas = 100\n",
    "dataset = get_balanced_dataset(data_list, subarea_size,  num_of_subareas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "238a06c3-6651-4c62-b606-6440e6cdf82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train dataset size: 22 batches\n",
      "Final validation dataset size: 8 batches\n",
      "Class counts in training dataset: Counter({1: 88, 0: 81, 2: 80, 3: 79})\n",
      "Class counts in validation dataset: Counter({1: 22, 0: 21, 2: 20, 3: 20})\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "split_ratio = 0.8\n",
    "\n",
    "training_data, validation_data = train_val_split(dataset, batch_size, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496e5b61-2276-4829-8200-0bfa4c241107",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b78fd39e-5c2b-443c-85d2-347fcfdf6870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 28s 1s/step - loss: 2.8601 - accuracy: 0.1982 - val_loss: 1.3870 - val_accuracy: 0.2410\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 29s 1s/step - loss: 1.4397 - accuracy: 0.0518 - val_loss: 1.3860 - val_accuracy: 0.2651\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 31s 1s/step - loss: 1.3891 - accuracy: 0.2683 - val_loss: 1.3860 - val_accuracy: 0.2651\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 29s 1s/step - loss: 1.3885 - accuracy: 0.2683 - val_loss: 1.3859 - val_accuracy: 0.2651\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 29s 1s/step - loss: 1.3883 - accuracy: 0.2683 - val_loss: 1.3859 - val_accuracy: 0.2651\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "history = train(model, training_data, validation_data, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203116bb-c0d6-4afe-9f0d-87553b31c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f949f-a7b2-419a-a92f-a2d9a58d8e45",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b7f07-e62e-408f-ae33-55c7b603871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to aggregate predictions using majority voting or average probabilities\n",
    "def aggregate_predictions(predictions, method='majority'):\n",
    "    if method == 'majority':\n",
    "        # Use majority vote across subareas for final class\n",
    "        final_prediction = np.argmax(np.bincount(predictions))\n",
    "    elif method == 'average':\n",
    "        # Average the class probabilities across subareas\n",
    "        avg_probabilities = np.mean(predictions, axis=0)\n",
    "\n",
    "        # Returns the index of highest class probability\n",
    "        final_prediction = np.argmax(avg_probabilities)\n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35320fb3-2efe-41b5-bd59-86ea2b313c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'average'\n",
    "\n",
    "final_predictions = []\n",
    "true_labels = [item['class'] for item in test_data]  # Ground truth labels\n",
    "\n",
    "# Process each image in the test_data individually\n",
    "for item in test_data:\n",
    "    # Generate subareas for this single image\n",
    "    subarea_dataset = create_dataset([item], subarea_size=subarea_size, subareas_per_image = 100)\n",
    "    subarea_dataset = subarea_dataset.map(lambda x, y: x)  # Keep only the image data\n",
    "    subarea_dataset = subarea_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Collect predictions for all subareas of this image\n",
    "    subarea_predictions = []\n",
    "    for subareas in subarea_dataset:\n",
    "        preds = model.predict(subareas)\n",
    "        subarea_predictions.extend(preds)  # Collect all subarea predictions\n",
    "\n",
    "    # Aggregate predictions for this image\n",
    "    subarea_predictions = np.array(subarea_predictions)\n",
    "    \n",
    "    if method == 'majority':\n",
    "        # Get class prediction for each subarea and apply majority voting\n",
    "        subarea_classes = np.argmax(subarea_predictions, axis=1)\n",
    "        final_class = aggregate_predictions(subarea_classes, method='majority')\n",
    "    elif method == 'average':\n",
    "        # Average class probabilities and choose the class with highest average\n",
    "        final_class = aggregate_predictions(subarea_predictions, method='average')\n",
    "\n",
    "    # Append the final prediction for this image\n",
    "    final_predictions.append(final_class)\n",
    "\n",
    "# Calculate the accuracy on the full images\n",
    "accuracy = np.mean(np.array(final_predictions) == np.array(true_labels))\n",
    "print(f\"Final Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5f3be-66e2-4925-a403-514904de28ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subarea_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211e1a8-44a4-40c6-82d3-22285ba223a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07bdde-1986-43dc-b105-5283a584768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [item['class'] for item in test_data]\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24baaea-8e57-4ec3-8695-5195a756b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the probabilities by averaging across subareas\n",
    "avg_probabilities = np.mean(subarea_predictions, axis=0)\n",
    "print(\"Averaged probabilities across subareas:\", avg_probabilities)\n",
    "\n",
    "# Get the predicted class from the averaged probabilities\n",
    "final_prediction_index = np.argmax(avg_probabilities)\n",
    "predicted_class = final_prediction_index + 1  # Convert our 1-based class label\n",
    "\n",
    "print(f\"Predicted class (in our labeling system): {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
